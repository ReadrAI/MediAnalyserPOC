{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept of the app\n",
    "1. Get Articles (once, weekly, daily, ...)\n",
    "\n",
    "    a. scraping & parsing\n",
    "    \n",
    "    b. API access\n",
    "\n",
    "    c. save to DB!!!\n",
    "\n",
    "2. Recognise keywords and main topic\n",
    "    \n",
    "    a. TF-IDF\n",
    "    \n",
    "    b. ???\n",
    "\n",
    "3. Group with other of the same topic\n",
    "    \n",
    "    a. Main topic matching\n",
    "    \n",
    "    b. Hierarchy (decision tree?)\n",
    "\n",
    "4. Find divergences\n",
    "\n",
    "    a. diff on keyword set\n",
    "\n",
    "    b. difference of opinion\n",
    "\n",
    "    c. difference of data sources\n",
    "\n",
    "    d. difference in \n",
    "\n",
    "5. Represent articles and divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lxml\n",
    "import json\n",
    "import shutil\n",
    "import codecs\n",
    "import requests\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import random\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from selenium.webdriver import Chrome\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import utils.NYTParser\n",
    "from utils.sql_utils import *\n",
    "from utils.scrape_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineNYT(name='nyt_20200723_1600', fetchSource=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver.get(\"https://www.nytimes.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible sources:\n",
    "\n",
    "    \"NYTimes\": \"https://www.nytimes.com/\",\n",
    "    \"BBC\": \"https://www.bbc.co.uk/\",\n",
    "    \"CNN\": \"https://edition.cnn.com/\",\n",
    "    \"FoxNews\": \"https://www.foxnews.com/\",\n",
    "    \"OAN\": \"https://www.oann.com/\"\n",
    "\n",
    "The Guardian, Yahoo news, Washington Post, Daily Mail, ...\n",
    "\n",
    "https://www.4imn.com/top200/ for more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(data, name):\n",
    "    with open('../raw_data/%s.txt' % name, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    with open('../raw_data/%s.txt' % name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "articles = fetchNewsAPI(content_type=\"articles\", url=('http://newsapi.org/v2/top-headlines?'\n",
    "        'pageSize=50&'\n",
    "        'page={page}&'\n",
    "        'language=en&'\n",
    "        'country=us&'\n",
    "        'apiKey=e30a64cfe1734e6794bdab67106590fa'))\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[0]['source']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_uuid = getSourceID('NewsAPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for a in articles:\n",
    "    print(a['source']['name'])\n",
    "    source_uuid = getSourceID(a['source']['name'])\n",
    "    if source_uuid is not None:\n",
    "        print(source_uuid)\n",
    "        a['article_url'] = a['url']\n",
    "        a['source_uuid'] = source_uuid\n",
    "        a['provider_uuid'] = provider_uuid\n",
    "        insertArticle(a)\n",
    "    else:\n",
    "        print(\"Could not match source:\", a['source']['name'])\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getSourceID('The Wall Street Journal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSourceID('New York Post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertArticle(params):\n",
    "\n",
    "    possible_article_params = ['article_url',\n",
    "                               'source_uuid',\n",
    "                               'provider_uuid',\n",
    "                               'title',\n",
    "                               'description',\n",
    "                               'author',\n",
    "                               'publishedAt',\n",
    "                               'updatedAt']\n",
    "\n",
    "    engine = getEngine()\n",
    "    params = {k: v for k, v in params.items() if k in possible_article_params}\n",
    "    sql = f\"\"\"insert into media.listing.articles ({\", \".join(params.keys())})\n",
    "            values ({list_for_sql(params.values())});\"\"\"\n",
    "    try:\n",
    "        engine.execute(sql)\n",
    "        if 'article_url' in params and 'description' in params:\n",
    "            article_uuid_sql = f\"\"\"select article_uuid from articles where article_url = '{params['article_url']}';\"\"\"\n",
    "            article_uuid = str(engine.execute(\n",
    "                article_uuid_sql).fetchall()[0][0])\n",
    "            description_sql = f\"\"\"insert into media.listing.article_contents\n",
    "                values ('{article_uuid}', '{params['description']}');\"\"\"\n",
    "            engine.execute(description_sql)\n",
    "    except (psycopg2.errors.UniqueViolation, sqlalchemy.exc.IntegrityError):\n",
    "        if 'article_url' in params:\n",
    "            print(\"Article article already exists:\", params['article_url'])\n",
    "        else:\n",
    "            print(\"Article url is required.\")\n",
    "        # todo manage article duplicates with difference or different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"abca\".replace(\"a\", \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineNYT(name='nyt_20200722_1000', fetchSource=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article_url = \"https://www.nytimes.com/2020/07/21/business/economy/coronavirus-unemployment-benefits.html\"\n",
    "test_article_uri = \"nyt://article/6fae2333-ff5a-5ac0-bcc5-34a2da53cbb3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}