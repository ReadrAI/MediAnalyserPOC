{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept of the app\n",
    "1. Get Articles (once, weekly, daily, ...)\n",
    "\n",
    "    a. scraping & parsing\n",
    "    \n",
    "    b. API access\n",
    "\n",
    "    c. save to DB!!!\n",
    "\n",
    "2. Recognise keywords and main topic\n",
    "    \n",
    "    a. TF-IDF\n",
    "    \n",
    "    b. ???\n",
    "\n",
    "3. Group with other of the same topic\n",
    "    \n",
    "    a. Main topic matching\n",
    "    \n",
    "    b. Hierarchy (decision tree?)\n",
    "\n",
    "4. Find divergences\n",
    "\n",
    "    a. diff on keyword set\n",
    "\n",
    "    b. difference of opinion\n",
    "\n",
    "    c. difference of data sources\n",
    "\n",
    "    d. difference in \n",
    "\n",
    "5. Represent articles and divergences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import lxml\n",
    "import json\n",
    "import shutil\n",
    "import codecs\n",
    "import requests\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import random\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from selenium.webdriver import Chrome\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import utils.NYTParser\n",
    "from utils.sql_utils import *\n",
    "from utils.scrape_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineNYT(name='nyt_20200723_1600', loadDisk=True)\n",
    "pipelineNYT(name='nyt_20200722_1000', loadDisk=True)\n",
    "pipelineNYT(name='nyt_20200727_1200', fetchSource=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineAPINews(name='apinews_202027_1200', fetchSource=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver.get(\"https://www.nytimes.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible sources:\n",
    "\n",
    "    \"NYTimes\": \"https://www.nytimes.com/\",\n",
    "    \"BBC\": \"https://www.bbc.co.uk/\",\n",
    "    \"CNN\": \"https://edition.cnn.com/\",\n",
    "    \"FoxNews\": \"https://www.foxnews.com/\",\n",
    "    \"OAN\": \"https://www.oann.com/\"\n",
    "\n",
    "The Guardian, Yahoo news, Washington Post, Daily Mail, ...\n",
    "\n",
    "https://www.4imn.com/top200/ for more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = pd.read_sql(\"select * from newsdb.sources\", getEngine())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = pd.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = pd.read_sql_table(\"articles\", getEngine())\n",
    "all_articles.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}